{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "See [guide](https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b8cc06f648e23a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "574da222403e9058",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "import src.Baseline\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from importlib import reload\n",
    "from src.Baseline import SoundDS, AudioClassifier, training, inference"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# only use aldfly and bkcchi for example purposes\n",
    "df = pd.read_csv('input/birdsong-recognition/train.csv')\n",
    "\n",
    "df = df[df['ebird_code'].isin(['aldfly', 'bkcchi'])]\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bcc341f63373622",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train():\n",
    "    wandb.init()\n",
    "\n",
    "    data_path = \"./input/birdsong-recognition/train_audio/\"\n",
    "\n",
    "    myds = SoundDS(df, data_path)\n",
    "\n",
    "    # Random split of 80:20 between training and validation\n",
    "    num_items = len(myds)\n",
    "    num_train = round(num_items * 0.8)\n",
    "    num_val = num_items - num_train\n",
    "    train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "\n",
    "    # Create training and validation data loaders\n",
    "    train_dl = torch.utils.data.DataLoader(train_ds,\n",
    "                                           batch_size=wandb.config.batch_size_train,\n",
    "                                           shuffle=True)\n",
    "    val_dl = torch.utils.data.DataLoader(val_ds,\n",
    "                                         batch_size=wandb.config.batch_size_val,\n",
    "                                         shuffle=False)\n",
    "\n",
    "    # Create the model and put it on the GPU if available\n",
    "    model = AudioClassifier()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    # Check that it is on Cuda\n",
    "    # var = next(model.parameters()).device\n",
    "\n",
    "    num_epochs = wandb.config.epochs\n",
    "    training(model, train_dl, num_epochs, device)\n",
    "\n",
    "    # Run inference on trained model with the validation set\n",
    "    inference(model, val_dl, device)\n",
    "    \n",
    "    # Save the model in the exchangeable ONNX format\n",
    "    torch.onnx.export(model, torch.randn(1, 1, 128, 201), \"model.onnx\")\n",
    "    \n",
    "    wandb.save(\"model.onnx\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d86e358e87f7fd9b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"Baseline Sweep\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"goal\": \"maximize\", \"name\": \"val_acc\"},\n",
    "    \"parameters\": {\n",
    "        \"epochs\": {\"min\": 7, \"max\": 20},\n",
    "        \"learning_rate\": {\"min\": 0, \"max\": 0.1, \"distribution\": \"log_uniform\"},\n",
    "        \n",
    "        \"batch_size_train\": {\"values\": [32]},\n",
    "        \"batch_size_val\": {\"values\": [32]},\n",
    "        \"anneal_strategy\": {\"values\": [\"linear\"]},\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"Baseline\", entity=\"swiss-birder\")\n",
    "\n",
    "wandb.agent(sweep_id, function=train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f142c37ad4663b3c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
